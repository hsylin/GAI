# Fundamentals and Applications of Generative AI Assignments

This repository contains all the assignments I completed for the **Fundamentals and Applications of Generative AI** course. Below is a brief overview of each assignment. More details can be found in the corresponding PDF files, and the code is available in each respective directory.

## 1. Arithmetic Text Generation
- **Objective**: Developed an arithmetic text generation model using RNN, GRU, and LSTM. The focus was on analyzing the effects of hyperparameters (batch size, learning rate) and training data distribution on model performance.
- **Assignment Details**: [Requirements](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project2a/GAI_Project2a_requirment.pdf) | [Report](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project2a/GAI_Project2a_report.pdf)
- **Code and Documentation**: The complete implementation and related files are available in the [`C14096073_GAI_Project2a`](https://github.com/hsylin/GAI/tree/main/C14096073_GAI_Project2a) directory.

## 2. Text Summarization
- **Objective**: Implemented text summarization on a Chinese dataset using T5 and GPT2 models. The project involved data preprocessing, model fine-tuning, and performance evaluation using ROUGE metrics. The performance of T5 and GPT2 models was compared for text summarization tasks.
- **Assignment Details**: [Requirements](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project2b/GAI_Project2b_requirment.pdf) | [Report](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project2b/GAI_Project2b_report.pdf)
- **Code and Documentation**: The complete implementation and related files are available in the [`C14096073_GAI_Project2b`](https://github.com/hsylin/GAI/tree/main/C14096073_GAI_Project2b) directory.

## 3. PEFT on GLUE Benchmarks
- **Objective**: Fine-tuned the BERT-base-uncased model on the MRPC and SST-2 datasets, comparing Parameter-Efficient Fine-Tuning (PEFT) methods such as Bitfit and LoRA to evaluate differences in model performance and efficiency.
- **Assignment Details**: [Requirements](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project3/GAI_Project3_requirment.pdf) | [Report](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project3/GAI_Project3_report.pdf)
- **Code and Documentation**: The complete implementation and related files are available in the [`C14096073_GAI_Project3`](https://github.com/hsylin/GAI/tree/main/C14096073_GAI_Project3) directory.

## 4. DDPM-DIP Image Generation
- **Objective**: Integrated Denoising Diffusion Probabilistic Models (DDPM) with Deep Image Prior (DIP) to enhance image generation quality. This project includes experiments comparing the standalone models with the combined approach, highlighting improvements in both image quality and generation speed.
- **Assignment Details**: [Requirements](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project4/requirement.pdf) | [Report](https://github.com/hsylin/GAI/blob/main/C14096073_GAI_Project4/report.pdf)
- **Code and Documentation**: The complete implementation and related files are available in the [`C14096073_GAI_Project4`](https://github.com/hsylin/GAI/tree/main/C14096073_GAI_Project4) directory.

## References for Project 4
- [Deep Image Prior](https://github.com/DmitryUlyanov/deep-image-prior)
- [Denoising Diffusion Probabilistic Models](https://github.com/bot66/MNISTDiffusion/tree/main)

